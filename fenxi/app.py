import streamlit as st
import cv2
import numpy as np
import plotly.graph_objects as go
from PIL import Image
import pandas as pd
import io
import zipfile
import time
import json
import gc
import os
from pathlib import Path

# å°è¯•å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from omni_engine import OmniVisualEngine, AestheticDiagnostician, BenchmarkManager, DEFAULT_ANALYSIS_PROMPT
    from benchmark_service import BenchmarkTrainer
except ImportError as e:
    st.error(f"âŒ ç¼ºå°‘æ ¸å¿ƒæ¨¡å—: {e}ã€‚è¯·ç¡®ä¿æ‰€æœ‰ .py æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
    st.stop()

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(page_title="å…¨èƒ½è§†è§‰åˆ†æ Pro (V18.3 Import Fix)", layout="wide", page_icon="ğŸ§¿")

st.markdown("""
    <style>
        .block-container { padding-top: 1rem; padding-bottom: 5rem; }
        h1 { font-size: 2.0rem !important; margin-bottom: 0.5rem !important; }
        .stButton button { border-radius: 8px; font-weight: 600; }
        .stMetric { background-color: #f8f9fa; padding: 10px; border-radius: 8px; border: 1px solid #eee; }
        .kobayashi-tag {
            display: inline-block;
            padding: 4px 12px;
            margin: 2px;
            border-radius: 16px;
            font-size: 0.85em;
            font-weight: 600;
            color: #333;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border: 1px solid #d1d5db;
        }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 2. çŠ¶æ€ç®¡ç†
# ==========================================
if 'batch_df' not in st.session_state: st.session_state.batch_df = None
if 'batch_zip' not in st.session_state: st.session_state.batch_zip = None
if 'batch_imgs_preview' not in st.session_state: st.session_state.batch_imgs_preview = [] 
if 'processing' not in st.session_state: st.session_state.processing = False
if 'benchmark_profile' not in st.session_state: st.session_state.benchmark_profile = None

# åˆå§‹åŒ–é»˜è®¤æç¤ºè¯
if 'analysis_prompt' not in st.session_state:
    st.session_state.analysis_prompt = DEFAULT_ANALYSIS_PROMPT

# ==========================================
# 3. ä¾§è¾¹æ ä¸å¼•æ“åˆå§‹åŒ–
# ==========================================
with st.sidebar:
    st.header("ğŸ§¿ è§†è§‰åˆ†æ Pro")
    st.caption("å†…æ ¸: SAM + U2-Net + VLM + PaddleOCR")
    
    # VLM é…ç½®
    with st.expander("ğŸ§  è§†è§‰å¤§æ¨¡å‹ (VLM) é…ç½®", expanded=False):
        _cfg_path = os.path.expanduser("~/.fenxi_vlm.json")
        def _load_vlm():
            try:
                with open(_cfg_path, 'r') as f:
                    c = json.load(f)
                return c.get('api_key', ''), c.get('endpoint', '')
            except Exception:
                return "", ""
        def _save_vlm(k, ep):
            try:
                with open(_cfg_path, 'w') as f:
                    json.dump({"api_key": k, "endpoint": ep}, f, indent=2)
                return True
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
                return False
        def _clear_vlm():
            try:
                if os.path.exists(_cfg_path): os.remove(_cfg_path)
                return True
            except Exception as e:
                st.error(f"æ¸…é™¤å¤±è´¥: {e}")
                return False
        _loaded_key, _loaded_ep = _load_vlm()
        vlm_key = st.text_input("Doubao API Key", value=_loaded_key or "", type="password", help="ç«å±±å¼•æ“ API Key")
        vlm_endpoint = st.text_input("Endpoint ID", value=_loaded_ep or "ep-20250203...", help="æ–¹èˆŸå¹³å°æ¥å…¥ç‚¹ ID")
        c_s1, c_s2 = st.columns(2)
        if c_s1.button("ä¿å­˜æ¥å…¥é…ç½®", use_container_width=True):
            if _save_vlm(vlm_key, vlm_endpoint):
                st.success("å·²ä¿å­˜æ¥å…¥é…ç½®")
                st.rerun()
        if c_s2.button("æ¸…é™¤æ¥å…¥é…ç½®", use_container_width=True):
            if _clear_vlm():
                st.success("å·²æ¸…é™¤æ¥å…¥é…ç½®")
                st.rerun()
        
        if vlm_key:
            st.success("âœ… VLM å·²å°±ç»ª (ä»…ç”¨äºç¾å­¦ç‚¹è¯„)")
        else:
            st.warning("âš ï¸ æœªé…ç½® VLM: å°†è·³è¿‡ AI ç‚¹è¯„ç¯èŠ‚")

    # æç¤ºè¯å·¥ç¨‹åŒºåŸŸ
    with st.expander("ğŸ“ æç¤ºè¯å·¥ç¨‹ (Prompt Engineering)", expanded=True):
        st.markdown("**ç¾å­¦åˆ†ææŒ‡ä»¤ (System Prompt)**")
        st.caption("å®šä¹‰ VLM å¦‚ä½•è¯„ä»·å›¾ç‰‡ã€‚ä½¿ç”¨ `{context_str}` ä»£è¡¨å›¾ç‰‡ä¸»ä½“ã€‚")
        ana_prompt_input = st.text_area(
            "Prompt å†…å®¹", 
            value=st.session_state.analysis_prompt, 
            height=200,
            key="ana_prompt_area"
        )
        
        if st.button("ğŸ’¾ ä¿å­˜æç¤ºè¯é…ç½®", type="primary", use_container_width=True):
            st.session_state.analysis_prompt = ana_prompt_input
            st.success("æç¤ºè¯å·²æ›´æ–°ï¼ä¸‹ä¸€æ¬¡åˆ†æå°†ç”Ÿæ•ˆã€‚")

    # æ¨¡å¼é€‰æ‹©
    mode = st.radio("å·¥ä½œæ¨¡å¼", ["ğŸ“¸ å•å›¾è¯Šæ–­", "ğŸ“¦ æ‰¹é‡å·¥å‚", "ğŸ† å»ºç«‹æ ‡æ†"], index=0)
    st.divider()
    
    # å¼ºåˆ¶åˆ·æ–°
    if st.button("ğŸ§¹ å¼ºåˆ¶åˆ·æ–°æ ¸å¿ƒå¼•æ“"):
        st.cache_resource.clear()
        gc.collect()
        st.rerun()
    
    # æ ‡æ†çŠ¶æ€
    current_profile = st.session_state.benchmark_profile
    if current_profile:
        if 'positive' in current_profile: st.success("âœ… åŒå‘æ ‡æ†ï¼šå·²æ¿€æ´»")
        else: st.success("âœ… å•å‘æ ‡æ†ï¼šå·²æ¿€æ´»")
        if st.button("æ¸…é™¤æ ‡æ†", use_container_width=True):
            st.session_state.benchmark_profile = None; st.rerun()
    
    # ç®—æ³•å‚æ•°
    with st.expander("âš™ï¸ åŸºç¡€ç®—æ³•å‚æ•°", expanded=False):
        p_width = st.slider("å¤„ç†åˆ†è¾¨ç‡", 256, 1024, 512, 128)
        k_num = st.slider("è‰²å½©èšç±»æ•°", 2, 8, 5)
        st.caption("é˜ˆå€¼å¾®è°ƒ")
        t_diag = st.slider("å¯¹è§’çº¿åˆ¤å®š", 0.1, 0.5, 0.3)
        t_sym_blur = st.slider("å¯¹ç§°æ¨¡ç³ŠK", 1, 51, 31, 2)
        ref_tex = st.slider("çº¹ç†åŸºå‡†", 10.0, 100.0, 50.0)
        t_clarity = st.slider("é«˜å…‰/æ¸…æ™°é˜ˆå€¼", 0.5, 0.9, 0.7)
    
    # æƒé‡å®¹å·® (17ä¸ªæŒ‡æ ‡)
    with st.expander("âš–ï¸ è¯„åˆ†æƒé‡ä¸å®¹å·®", expanded=False):
        dims_geo = [
            ('comp_balance_score', 'æ„ŸçŸ¥å¹³è¡¡'), ('comp_layout_score', 'æ„å›¾åŒ¹é…'), 
            ('comp_negative_space_score', 'å‘¼å¸æ„Ÿ'), ('comp_visual_flow_score', 'è§†çº¿å¼•å¯¼'),
            ('comp_visual_order_score', 'è§†è§‰ç§©åº')
        ]
        dims_color = [
            ('color_saturation', 'é¥±å’Œåº¦'), ('color_brightness', 'äº®åº¦'), 
            ('color_warmth', 'æš–è‰²è°ƒ'), ('color_contrast', 'å¯¹æ¯”åº¦'), 
            ('color_clarity', 'æ¸…æ™°åº¦'), ('color_harmony', 'å’Œè°åº¦')
        ]
        dims_text = [
            ('text_alignment_score', 'æ’ç‰ˆå¯¹é½'), ('text_hierarchy_score', 'å±‚çº§æ€§'),
            ('text_content_ratio', 'å†…å®¹å æ¯”'), ('fg_text_legibility', 'æ˜“è¯»æ€§'), ('fg_text_contrast', 'æ–‡å­—å¯¹æ¯”')
        ]
        dims_content = [('fg_color_diff', 'ä¸»ä½“è‰²å·®'), ('fg_area_diff', 'ä¸»ä½“å æ¯”'), ('fg_texture_diff', 'çº¹ç†å·®å¼‚')]
        
        loaded_weights = current_profile.get('weights', {}) if current_profile else {}
        loaded_tols = current_profile.get('tolerances', {}) if current_profile else {}
        
        tab_w, tab_t = st.tabs(["ğŸ“Š æƒé‡", "ğŸ¯ å®¹å·®"])
        final_weights = {}
        final_tols = {}
        
        def render_sliders(tab, category_name, dims, is_weight=True):
            tab.caption(f"**{category_name}**")
            for k, label in dims:
                if is_weight:
                    default_val = float(loaded_weights.get(k, 1.0)) 
                    key = f"w_{k}"
                    if key not in st.session_state: st.session_state[key] = default_val
                    final_weights[k] = tab.slider(label, 0.0, 5.0, step=0.1, key=key)
                else:
                    val_from_file = loaded_tols.get(k)
                    if not val_from_file and current_profile and 'positive' in current_profile:
                        if k in current_profile['positive'] and isinstance(current_profile['positive'][k], dict):
                             val_from_file = current_profile['positive'][k].get('tolerance')
                    elif not val_from_file and current_profile and k in current_profile and isinstance(current_profile[k], dict):
                        val_from_file = current_profile[k].get('tolerance')
                    default_val = float(val_from_file) if val_from_file else 0.2
                    max_val = 5.0 if 'dist' in k else 1.0 
                    key = f"t_{k}"
                    if key not in st.session_state: st.session_state[key] = default_val
                    final_tols[k] = tab.slider(label, 0.0, max_val, step=0.01, key=key)
                    
        with tab_w:
            render_sliders(tab_w, "ğŸ“ æ„å›¾/ç§©åº", dims_geo, True)
            render_sliders(tab_w, "ğŸ¨ è‰²å½©", dims_color, True)
            render_sliders(tab_w, "ğŸ…°ï¸ æ–‡å­—æ’ç‰ˆ", dims_text, True)
            render_sliders(tab_w, "ğŸŒ— å›¾åº•", dims_content, True)
        with tab_t:
            render_sliders(tab_t, "ğŸ“ æ„å›¾/ç§©åº", dims_geo, False)
            render_sliders(tab_t, "ğŸ¨ è‰²å½©", dims_color, False)
            render_sliders(tab_t, "ğŸ…°ï¸ æ–‡å­—æ’ç‰ˆ", dims_text, False)
            render_sliders(tab_t, "ğŸŒ— å›¾åº•", dims_content, False)

    config = {
        'process_width': p_width, 'seg_kmeans_k': k_num, 'comp_diag_slope': t_diag,
        'comp_sym_blur_k': t_sym_blur, 'fg_tex_norm': ref_tex, 'color_clarity_thresh': t_clarity,
        'comp_thirds_slope': 0.2, 'comp_sym_tolerance': 120.0, 'text_score_thresh': 60.0,
        'weights': final_weights, 'tolerances': final_tols,
        'analysis_prompt': st.session_state.analysis_prompt
    }

# åˆå§‹åŒ–å¼•æ“
@st.cache_resource
def get_engine(api_key, endpoint, _version="v18.3_no_circular"):
    return OmniVisualEngine(vlm_api_key=api_key, vlm_endpoint=endpoint)

engine = get_engine(vlm_key, vlm_endpoint)

# ==========================================
# 4. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================

def make_serializable(obj):
    if isinstance(obj, (np.integer, np.floating)): return float(obj)
    if isinstance(obj, np.ndarray): return obj.tolist()
    return obj

def calculate_dual_score(data, profile, bm_manager):
    is_dual = 'positive' in profile and isinstance(profile['positive'], dict)
    if is_dual:
        res_pos = bm_manager.score_against_benchmark(data, profile['positive'])
        score_pos = res_pos['total_score']
        score_neg = 0
        if 'negative' in profile and profile['negative']:
            res_neg = bm_manager.score_against_benchmark(data, profile['negative'])
            score_neg = res_neg['total_score'] 
        penalty_factor = 0.4 
        final_score = max(0, min(100, score_pos - (score_neg * penalty_factor)))
        if final_score >= 90: rating = "S (å“è¶Š)"
        elif final_score >= 80: rating = "A (ä¼˜ç§€)"
        elif final_score >= 70: rating = "B (è‰¯å¥½)"
        elif final_score >= 60: rating = "C (åˆæ ¼)"
        else: rating = "D (ä¸åˆæ ¼)"
        return {
            'total_score': final_score, 'rating_level': rating, 'mode': 'åŒå‘æ ‡æ†',
            'details': res_pos['details'], 'score_breakdown': {'pos': score_pos, 'neg': score_neg}
        }
    else:
        res = bm_manager.score_against_benchmark(data, profile)
        res['mode'] = 'å•å‘æ ‡æ†'
        res['score_breakdown'] = None
        return res

def normalize_values(source, is_profile=False):
    def get(k): 
        val = source.get(k, {}).get('target', 0) if is_profile else getattr(source, k, 0)
        return float(val) if val is not None else 0.0
    
    return [
        get('comp_balance_score'), get('comp_layout_score'), get('comp_negative_space_score'), 
        get('comp_visual_flow_score'), get('comp_visual_order_score'),
        
        get('color_warmth')*100, get('color_saturation')*100, get('color_brightness')*100, min(100, (get('color_contrast')/0.3)*100), get('color_clarity')*100, get('color_harmony'),
        
        get('text_alignment_score'), get('text_hierarchy_score'), min(100, get('text_content_ratio') * 2), get('fg_text_legibility'), get('fg_text_contrast'),
        
        get('fg_area_diff')*100, min(100, get('fg_color_diff')), get('fg_texture_diff')*100
    ]

# ==========================================
# 5. æ‰¹é‡å¤„ç†é€»è¾‘
# ==========================================
def run_batch_process(files, cfg, need_zip, profile=None):
    # [Lazy Import Fix]
    try:
        from benchmark_service import BenchmarkTrainer
    except ImportError:
        st.error("æ— æ³•åŠ è½½æ ‡æ†æœåŠ¡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§ã€‚")
        return

    st.session_state.processing = True
    st.session_state.batch_logs = []
    
    ALL_DIMS_MAPPING = [
        ('comp_balance_score', 'æ„å›¾_æ„ŸçŸ¥å¹³è¡¡'), ('comp_layout_score', 'æ„å›¾_æ¨¡æ¿åŒ¹é…'),
        ('comp_negative_space_score', 'æ„å›¾_å‘¼å¸æ„Ÿ'), ('comp_visual_flow_score', 'æ„å›¾_è§†çº¿å¼•å¯¼'),
        ('comp_visual_order_score', 'æ„å›¾_è§†è§‰ç§©åº'),
        ('color_saturation', 'è‰²å½©_é¥±å’Œåº¦'), ('color_brightness', 'è‰²å½©_äº®åº¦'),
        ('color_warmth', 'è‰²å½©_æš–è‰²è°ƒ'), ('color_contrast', 'è‰²å½©_å¯¹æ¯”åº¦'),
        ('color_clarity', 'è‰²å½©_æ¸…æ™°åº¦'), ('color_harmony', 'è‰²å½©_å’Œè°åº¦'),
        ('text_alignment_score', 'æ–‡å­—_æ’ç‰ˆå¯¹é½'), ('text_hierarchy_score', 'æ–‡å­—_å±‚çº§æ€§'),
        ('text_content_ratio', 'æ–‡å­—_å†…å®¹å æ¯”'), ('fg_text_legibility', 'æ–‡å­—_æ˜“è¯»æ€§'), ('fg_text_contrast', 'æ–‡å­—_å¯¹æ¯”åº¦'),
        ('fg_color_diff', 'å›¾åº•_è‰²å·®'), ('fg_area_diff', 'å›¾åº•_å æ¯”'), ('fg_texture_diff', 'å›¾åº•_çº¹ç†å·®')
    ]
    
    rows = []; diff_rows = []; raw_json_list = []
    zip_buffer = io.BytesIO() if need_zip else None
    zf = zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) if need_zip else None
    bm_manager = BenchmarkManager() if profile else None
    total = len(files); progress_bar = st.progress(0); status_text = st.empty()
    
    for idx, f in enumerate(files):
        try:
            status_text.text(f"Processing {idx+1}/{total}: {f.name}")
            f.seek(0); f_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8); img_bgr = cv2.imdecode(f_bytes, cv2.IMREAD_COLOR)
            if img_bgr is None: continue
            d = engine.analyze(img_bgr, config=cfg)
            if profile:
                if 'positive' in profile: res = calculate_dual_score(d, profile, bm_manager); target_dict = profile['positive']
                else: res = bm_manager.score_against_benchmark(d, profile); target_dict = profile
                final_score = res['total_score']; final_rating = res['rating_level']; mode_str = f"æ ‡æ† ({res.get('mode','é»˜è®¤')})"
            else:
                rep = AestheticDiagnostician.generate_report(d, config=cfg)
                final_score = rep['total_score']; final_rating = rep['rating_level']; mode_str = "é€šç”¨æ¨¡å¼"; target_dict = {}
            base_info = {"æ–‡ä»¶å": f.name, "ç»¼åˆå¾—åˆ†": final_score, "è¯„çº§": final_rating, "æ¨¡å¼": mode_str}
            row_data = base_info.copy(); diff_data = base_info.copy()
            for key, label in ALL_DIMS_MAPPING:
                val = getattr(d, key, 0) or 0
                if key == 'fg_text_legibility' and not getattr(d, 'fg_text_present', False): val = 0
                row_data[label] = round(val, 2)
                if profile and key in target_dict: t_val = target_dict[key].get('target', 0); diff_data[f"Î”_{label}"] = round(val - t_val, 2)
                else: diff_data[f"Î”_{label}"] = 0
            if hasattr(d, 'kobayashi_tags') and d.kobayashi_tags: row_data['å°è±¡æ ‡ç­¾'] = ", ".join(d.kobayashi_tags)
            rows.append(row_data); diff_rows.append(diff_data)
            raw_obj = {k: make_serializable(getattr(d, k)) for k, _ in ALL_DIMS_MAPPING}; raw_obj['filename'] = f.name; raw_json_list.append(raw_obj)
            if zf:
                vis_map = {
                    'v_balance': 'vis_saliency_heatmap', 'v_layout': 'vis_layout_template', 
                    'v_flow': 'vis_visual_flow', 'v_order': 'vis_visual_order',
                    'v_sat': 'vis_saturation', 'v_bri': 'vis_brightness', 'v_text_leg': 'vis_text_analysis', 'v_text_lay': 'vis_text_design',
                    'v_col_harm': 'vis_color_harmony'
                }
                base_name = f.name.rsplit('.', 1)[0]
                for excel_key, attr_name in vis_map.items():
                    img_data = getattr(d, attr_name, None)
                    if img_data is not None:
                        if hasattr(img_data, 'dtype') and img_data.dtype != np.uint8: img_data = img_data.astype(np.uint8)
                        if len(img_data.shape) == 2: img_data = cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB)
                        _, buf = cv2.imencode('.png', cv2.cvtColor(img_data, cv2.COLOR_RGB2BGR)); zf.writestr(f"diagnostics/{base_name}_{excel_key}.png", buf.tobytes())
            del d; del img_bgr; 
            if idx % 5 == 0: gc.collect()
        except Exception as e: st.session_state.batch_logs.append(f"Error {f.name}: {e}")
        progress_bar.progress((idx + 1) / total)
    if zf: zf.close()
    st.session_state.batch_df = pd.DataFrame(rows); st.session_state.batch_diff_df = pd.DataFrame(diff_rows); st.session_state.batch_raw_json = raw_json_list; st.session_state.batch_zip = zip_buffer.getvalue() if need_zip else None; st.session_state.processing = False; gc.collect()

# ==========================================
# 6. ä¸»ç•Œé¢é€»è¾‘ (æŒ‰æ¨¡å¼)
# ==========================================

# --- æ¨¡å¼ 1: æ‰¹é‡å·¥å‚ ---
if mode == "ğŸ“¦ æ‰¹é‡å·¥å‚": 
    st.title("ğŸ“¦ æ‰¹é‡å¤„ç†ä¸­å¿ƒ") 
    with st.container(): batch_files = st.file_uploader("ğŸ“‚ é€‰æ‹©å›¾ç‰‡", type=["jpg","png","jpeg"], accept_multiple_files=True) 
    if batch_files: 
        st.divider() 
        c1, c2, c3 = st.columns([2, 1, 1]) 
        with c1: st.info(f"å·²åŠ è½½ **{len(batch_files)}** å¼ å›¾ç‰‡") 
        with c2: opt_zip = st.checkbox("ç”Ÿæˆå…¨å¥—å›¾åŒ…", value=True) 
        with c3: 
            st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ", type="primary", use_container_width=True, 
                      on_click=run_batch_process, 
                      args=(batch_files, config, opt_zip, st.session_state.benchmark_profile)) 
    
    if st.session_state.processing: 
        st.divider(); st.warning("â³ æ­£åœ¨è¿›è¡Œå…¨ç»´åº¦åˆ†æï¼Œè¯·ç¨å€™...") 
        with st.expander("å®æ—¶æ—¥å¿—"): st.text("\n".join(st.session_state.batch_logs[-10:])) 
    
    if st.session_state.batch_df is not None: 
        st.divider(); st.subheader("3. ç»“æœäº¤ä»˜") 
        st.dataframe(st.session_state.batch_df, use_container_width=True, height=400) 
        d1, d2, d3 = st.columns(3) 
        with d1: st.download_button("ğŸ“Š å®Œæ•´æŠ¥è¡¨ (Excel)", st.session_state.batch_df.to_csv().encode('utf-8-sig'), "Report.csv", "text/csv", type="primary", use_container_width=True)
        with d2: 
            if 'batch_raw_json' in st.session_state: 
                json_str = json.dumps(st.session_state.batch_raw_json, default=make_serializable, indent=4) 
                st.download_button("âš™ï¸ åŸå§‹å‚æ•° (JSON)", json_str, "Raw_Parameters.json", "application/json", use_container_width=True) 
        with d3: 
            if st.session_state.batch_zip: st.download_button("ğŸ“¦ è¯Šæ–­å›¾åŒ… (ZIP)", st.session_state.batch_zip, "Diagnostic_Images.zip", "application/zip", use_container_width=True) 

# --- æ¨¡å¼ 2: å•å›¾è¯Šæ–­ ---
elif mode == "ğŸ“¸ å•å›¾è¯Šæ–­":
    st.title("ğŸ§¿ å•å›¾æ·±åº¦è¯Šæ–­")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['jpg','png','jpeg'])
    if uploaded_file:
        image_pil = Image.open(uploaded_file); img_bgr = cv2.cvtColor(np.array(image_pil.convert('RGB')), cv2.COLOR_RGB2BGR)
        with st.spinner("AI æ­£åœ¨è¿›è¡Œå…¨ç»´åº¦æ‰«æ (U2-Netæ£€æµ‹ + SAMåˆ†å‰² + VLMç‚¹è¯„)..."):
            try:
                data = engine.analyze(img_bgr, config=config)
                rep = AestheticDiagnostician.generate_report(data, config=config)
                is_bench = st.session_state.benchmark_profile is not None; bench_details = {}
                if is_bench:
                    bm = BenchmarkManager(); res = calculate_dual_score(data, st.session_state.benchmark_profile, bm)
                    final_score = res['total_score']; final_rating = res['rating_level']; bench_details = res['details']; mode_display = res.get('mode', 'æ ‡æ†')
                else: final_score = rep['total_score']; final_rating = rep['rating_level']; mode_display = "é€šç”¨"
            except Exception as e:
                st.error(f"Analysis Failed: {e}")
                st.stop()

        c1, c2 = st.columns([1, 1.2])
        with c1:
            st.image(image_pil, use_container_width=True)
            st.metric("ğŸ† ç»¼åˆå¾—åˆ†", f"{final_score:.1f}", delta=f"{final_rating} ({mode_display})")
            st.divider()
            
            # [New] å±•ç¤º VLM è¯­ä¹‰ç»“æœ
            st.subheader("ğŸ§  AI è§†è§‰é¡¾é—®")
            if hasattr(data, 'semantic_style') and data.semantic_style and data.semantic_style != "N/A":
                st.info(f"ğŸ¨ **é£æ ¼**: {data.semantic_style} (Score: {data.semantic_score})")
                st.markdown(f"> ğŸ“ **ç‚¹è¯„**: {data.vlm_critique}")
            elif not vlm_key:
                st.warning("æœªé…ç½® VLM API Keyï¼Œæ— æ³•å±•ç¤ºè¯­ä¹‰ç‚¹è¯„ã€‚")
            
            # å¤ç”¨ Smart Card å‡½æ•°
            def smart_card(col, label, key, unit="", multiplier=1.0):
                raw_val = getattr(data, key, 0); 
                if raw_val is None: raw_val = 0
                if is_bench and key in bench_details:
                    item = bench_details[key]; score = item['score']; target = item['target'] * multiplier; actual = item['actual'] * multiplier
                    state = "normal" if score >= 80 else ("off" if score >= 60 else "inverse")
                    col.metric(label, f"{score:.0f}åˆ†", f"å®{actual:.1f}{unit}/æ ‡{target:.1f}{unit}", delta_color=state)
                else: col.metric(label, f"{raw_val*multiplier:.1f}{unit}")

            st.divider()
            st.caption("ğŸ¨ è‰²å½©æ°›å›´ (6é¡¹)")
            if hasattr(data, 'kobayashi_tags') and data.kobayashi_tags:
                tags_html = "".join([f'<span class="kobayashi-tag">{tag}</span>' for tag in data.kobayashi_tags])
                st.markdown(f"**å°è±¡æ ‡ç­¾:** {tags_html}", unsafe_allow_html=True)
            c_r1_1, c_r1_2, c_r1_3 = st.columns(3); smart_card(c_r1_1, "é¥±å’Œåº¦", "color_saturation", "%", 100); smart_card(c_r1_2, "äº®åº¦", "color_brightness", "%", 100); smart_card(c_r1_3, "æš–è‰²è°ƒ", "color_warmth", "%", 100)
            c_r2_1, c_r2_2, c_r2_3 = st.columns(3); smart_card(c_r2_1, "å¯¹æ¯”åº¦", "color_contrast", "", 1.0); smart_card(c_r2_2, "æ¸…æ™°åº¦", "color_clarity", "%", 100); smart_card(c_r2_3, "å’Œè°åº¦", "color_harmony", "", 1.0)

            st.divider(); st.caption("ğŸ“ æ„å›¾ä¸è§†è§‰ç§©åº (5é¡¹)")
            g_r1_1, g_r1_2, g_r1_3 = st.columns(3)
            smart_card(g_r1_1, "æ„ŸçŸ¥å¹³è¡¡", "comp_balance_score")
            
            # [New] Interactive Composition Template Switcher
            layout_str = getattr(data, 'comp_layout_type', 'N/A')
            smart_card(g_r1_2, f"æ„å›¾åŒ¹é… ({layout_str})", "comp_layout_score")
            
            smart_card(g_r1_3, "è§†è§‰ç§©åº", "comp_visual_order_score")
            g_r2_1, g_r2_2 = st.columns(2)
            smart_card(g_r2_1, "å‘¼å¸æ„Ÿ", "comp_negative_space_score")
            smart_card(g_r2_2, "è§†çº¿å¼•å¯¼", "comp_visual_flow_score")

            st.divider(); st.caption("ğŸ…°ï¸ æ–‡å­—æ’ç‰ˆ (5é¡¹)")
            t_r1_1, t_r1_2 = st.columns(2); smart_card(t_r1_1, "æ’ç‰ˆå¯¹é½", "text_alignment_score"); smart_card(t_r1_2, "å±‚çº§æ€§", "text_hierarchy_score")
            t_r2_1, t_r2_2, t_r2_3 = st.columns(3); 
            smart_card(t_r2_1, "å†…å®¹å æ¯”", "text_content_ratio", "%"); 
            if getattr(data, 'fg_text_present', False): 
                smart_card(t_r2_2, "æ˜“è¯»æ€§", "fg_text_legibility")
                smart_card(t_r2_3, "æ–‡å­—å¯¹æ¯”", "fg_text_contrast")
            else: 
                t_r2_2.metric("æ˜“è¯»æ€§", "N/A", "æ— æ˜¾è‘—æ–‡å­—")
                t_r2_3.metric("æ–‡å­—å¯¹æ¯”", "N/A", "æ— æ˜¾è‘—æ–‡å­—")

            st.divider(); st.caption("ğŸŒ— å›¾åº•ä¸ä¿¡æ¯ (3é¡¹)")
            f_r1_1, f_r1_2, f_r1_3 = st.columns(3)
            smart_card(f_r1_1, "ä¸»ä½“è‰²å·®", "fg_color_diff")
            smart_card(f_r1_2, "ä¸»ä½“å æ¯”", "fg_area_diff", "%", 100)
            smart_card(f_r1_3, "çº¹ç†å·®å¼‚", "fg_texture_diff")
            
        with c2:
            st.subheader("ğŸ“Š ç»´åº¦é›·è¾¾ (19æ ¸å¿ƒ)")
            cats = ['æ„ŸçŸ¥å¹³è¡¡','æ„å›¾åŒ¹é…','å‘¼å¸æ„Ÿ','è§†çº¿å¼•å¯¼', 'è§†è§‰ç§©åº', 'æš–è‰²','é¥±å’Œ','äº®åº¦','å¯¹æ¯”','æ¸…æ™°','å’Œè°', 'æ’ç‰ˆå¯¹é½', 'å±‚çº§', 'å†…å®¹æ¯”', 'æ˜“è¯»', 'æ–‡å­—å¯¹æ¯”', 'å æ¯”', 'è‰²å·®', 'çº¹ç†']
            vals = normalize_values(data, False); fig = go.Figure()
            fig.add_trace(go.Scatterpolar(r=vals, theta=cats, fill='toself', name='å½“å‰å›¾ç‰‡', line_color='#3498db'))
            if is_bench:
                bench_vals = normalize_values(st.session_state.benchmark_profile['positive'] if 'positive' in st.session_state.benchmark_profile else st.session_state.benchmark_profile, True)
                fig.add_trace(go.Scatterpolar(r=bench_vals, theta=cats, fill='toself', name='æ ‡æ†åŸºå‡†', line_color='#2ecc71', opacity=0.4))
            fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=True, height=350, margin=dict(t=20, b=20, l=40, r=40))
            st.plotly_chart(fig, use_container_width=True)

            st.subheader("ğŸ” è¯Šæ–­å›¾è°±")
            t_comp, t_color, t_fg, t_text = st.tabs(["ğŸ“ æ„å›¾/ç§©åº", "ğŸ¨ è‰²å½©", "ğŸŒ— å›¾åº•", "ğŸ…°ï¸ æ’ç‰ˆ"])
            with t_comp:
                c1, c2 = st.columns(2); 
                if data.vis_saliency_heatmap is not None: c1.image(data.vis_saliency_heatmap, caption="è§†è§‰å¹³è¡¡çƒ­åŠ›å›¾", use_container_width=True)
                
                # [New] Interactive Composition Template Switcher
                if getattr(data, 'vis_layout_dict', None):
                    # Sort templates by score descending
                    sorted_items = sorted(data.vis_layout_dict.items(), key=lambda x: x[1]['score'], reverse=True)
                    options = [f"{k} ({v['score']:.1f})" for k, v in sorted_items]
                    
                    # Create radio button for selection
                    selected_option_label = c2.radio("é€‰æ‹©æ„å›¾æ¨¡æ¿", options, horizontal=True, label_visibility="collapsed")
                    
                    # Extract key to get image
                    if selected_option_label:
                        selected_key = selected_option_label.split(" (")[0]
                        selected_vis_data = data.vis_layout_dict.get(selected_key)
                        if selected_vis_data:
                            c2.image(selected_vis_data['vis'], caption=f"æ„å›¾åŒ¹é…: {selected_key} (å¾—åˆ†: {selected_vis_data['score']:.1f})", use_container_width=True)
                elif data.vis_layout_template is not None: 
                     # Fallback for old/single image
                     c2.image(data.vis_layout_template, caption=f"æœ€ä½³æ„å›¾: {data.comp_layout_type}", use_container_width=True)

                c3, c4 = st.columns(2)
                if data.vis_visual_flow is not None: c3.image(data.vis_visual_flow, caption="è§†çº¿å¼•å¯¼åˆ†æ", use_container_width=True)
                if data.vis_visual_order is not None: c4.image(data.vis_visual_order, caption="è§†è§‰ç§©åº (è§’åº¦ç†µ)", use_container_width=True)
            with t_color:
                c1, c2 = st.columns(2)
                if data.vis_warmth is not None: c1.image(data.vis_warmth, caption="å†·æš–åˆ†å¸ƒ", use_container_width=True)
                if data.vis_color_harmony is not None: c2.image(data.vis_color_harmony, caption="å’Œè°è‰²è½® (Top5ä¸»è‰²)", use_container_width=True)
                c3, c4 = st.columns(2)
                if data.vis_brightness is not None: c3.image(data.vis_brightness, caption="äº®åº¦(J)åˆ†å¸ƒ", use_container_width=True)
                if data.vis_clarity is not None: c4.image(data.vis_clarity, caption="æ¸…æ™°åº¦/é«˜å…‰", use_container_width=True)
            with t_fg:
                c1, c2 = st.columns(2)
                if data.vis_mask is not None: c1.image(data.vis_mask, caption="æ™ºèƒ½åˆ†å‰² (VLMæ£€æµ‹ + SAMç²¾ä¿®)", use_container_width=True)
                if data.vis_color_contrast is not None: c2.image(data.vis_color_contrast, caption="è‰²å½©å¯¹æ¯”", use_container_width=True)
                c3, c4 = st.columns(2)
                if data.vis_edge_composite is not None: c3.image(data.vis_edge_composite, caption="çº¹ç†å¯¹æ¯”", use_container_width=True)
            with t_text:
                c1, c2 = st.columns(2)
                if data.vis_text_analysis is not None: c1.image(data.vis_text_analysis, caption="æ˜“è¯»æ€§åˆ†æ", use_container_width=True)
                if data.vis_text_design is not None: c2.image(data.vis_text_design, caption="æ’ç‰ˆåˆ†æ (å¯¹é½/å±‚çº§)", use_container_width=True)

# --- æ¨¡å¼ 3: å»ºç«‹æ ‡æ† (Restored) --- 
elif mode == "ğŸ† å»ºç«‹æ ‡æ†":
    st.title("ğŸ† å»ºç«‹è¡Œä¸šè§†è§‰æ ‡æ†")
    
    # [New] å¢åŠ æ ‡æ†åŠ è½½åŠŸèƒ½
    with st.expander("ğŸ“‚ åŠ è½½å·²æœ‰æ ‡æ†é…ç½® (Load Profile)", expanded=False):
        uploaded_profile = st.file_uploader("ä¸Šä¼  benchmark_profile.json", type=["json"], key="profile_loader")
        if uploaded_profile is not None:
            try:
                loaded_data = json.load(uploaded_profile)
                # ç®€å•æ ¡éªŒ
                if 'weights' in loaded_data and 'tolerances' in loaded_data:
                    if st.button("ç¡®è®¤åŠ è½½æ­¤é…ç½®", type="primary"):
                        st.session_state.benchmark_profile = loaded_data
                        st.success("âœ… æ ‡æ†é…ç½®å·²åŠ è½½ï¼ä¾§è¾¹æ æƒé‡ä¸å‚æ•°å·²æ›´æ–°ã€‚")
                        time.sleep(1)
                        st.rerun()
                else:
                    st.warning("âš ï¸ JSON æ ¼å¼ä¸ç¬¦åˆæ ‡æ†é…ç½®æ–‡ä»¶è§„èŒƒ (ç¼ºå°‘ weights æˆ– tolerances å­—æ®µ)")
            except Exception as e:
                st.error(f"æ— æ³•è§£ææ–‡ä»¶: {e}")

    st.divider()

    c_high, c_low = st.columns(2)
    with c_high: files_high = st.file_uploader("High (æ­£å‘)", accept_multiple_files=True)
    with c_low: files_low = st.file_uploader("Low (è´Ÿå‘)", accept_multiple_files=True)
    
    if files_high and st.button("ğŸš€ å¼€å§‹è®­ç»ƒ"):
        # [Lazy Import] 
        try:
            from benchmark_service import BenchmarkTrainer
        except ImportError:
            st.error("æ— æ³•å¯¼å…¥ benchmark_service")
            st.stop()
            
        trainer = BenchmarkTrainer()
        gc.collect()
        with st.spinner("Training..."):
            try:
                # [Update] Handle dict return from train
                profile, dist_data_dict, stats = trainer.train(files_high, files_low, config)
                st.session_state.benchmark_profile = profile
                st.success(f"è®­ç»ƒå®Œæˆï¼(æ­£å‘:{stats['pos_count']}, è´Ÿå‘:{stats['neg_count']})")
                
                with st.expander("ğŸ“ˆ ç‰¹å¾åˆ†å¸ƒå¯è§†åŒ– (æ­£å‘ vs è´Ÿå‘)", expanded=True): 
                    tab_pos, tab_neg = st.tabs(["ğŸŸ¢ æ­£å‘æ ·æœ¬åˆ†å¸ƒ", "ğŸ”´ è´Ÿå‘æ ·æœ¬åˆ†å¸ƒ"])
                    
                    with tab_pos:
                        fig_pos = go.Figure() 
                        # Use dist_data_dict['pos']
                        for k, vals in dist_data_dict['pos'].items(): 
                            fig_pos.add_trace(go.Box(y=vals, name=k, boxpoints='all', jitter=0.3, marker_color='green')) 
                        fig_pos.update_layout(height=400, showlegend=False, title="æ­£å‘æ ‡æ†ç‰¹å¾åˆ†å¸ƒ (0-100)") 
                        st.plotly_chart(fig_pos, use_container_width=True)
                    
                    with tab_neg:
                        # Use dist_data_dict['neg']
                        if dist_data_dict.get('neg'):
                            fig_neg = go.Figure() 
                            for k, vals in dist_data_dict['neg'].items(): 
                                fig_neg.add_trace(go.Box(y=vals, name=k, boxpoints='all', jitter=0.3, marker_color='red')) 
                            fig_neg.update_layout(height=400, showlegend=False, title="è´Ÿå‘æ ·æœ¬ç‰¹å¾åˆ†å¸ƒ (0-100)") 
                            st.plotly_chart(fig_neg, use_container_width=True)
                        else:
                            st.info("æœªä¸Šä¼ è´Ÿå‘æ ·æœ¬ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”åˆ†å¸ƒå›¾ã€‚")
                
                json_str = json.dumps(profile, default=make_serializable, indent=4) 
                st.download_button("ğŸ“¦ ä¸‹è½½å®Œæ•´é…ç½®", json_str, "benchmark_profile.json", "application/json", type="primary")
            except Exception as e:
                st.error(f"è®­ç»ƒå¤±è´¥: {str(e)}")